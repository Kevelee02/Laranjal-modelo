# -*- coding: utf-8 -*-
"""projet_t001.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u3uuh5I_Pr6cDUEiHCYKPib_Ya0mGsXr
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from feature_engine import encoding
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score
from sklearn import metrics
from sklearn import pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

file_path = 'https://raw.githubusercontent.com/atlantico-academy/datasets/refs/heads/main/orange_quality.csv'

dados = pd.read_csv(file_path)

dados.head()

"""# Dicionário dos dados
Size (cm) - Tamanho da laranja em centímetros

Weight (g) - Peso da laranja em gramas

Brix (Sweetness) - Nível de doçura da laranja

pH (Acidity) - Nível de acidez da laranja

Softness (1-5) - Suavidade da laranja (escala de 1 a 5)

HarvestTime (days) - Tempo desde a colheita em dias

Ripeness (1-5) - Maturidade da laranja (escala de 1 a 5)

Color - Cor da laranja

Variety - Variedade da laranja

Blemishes (Y/N) - Presença de manchas ou imperfeições (Sim/Não)

Quality (1-5) - Qualidade geral da laranja (escala de 1 a 5)
"""

dados.head()

dados.describe().T

dados.info()

dados.isnull().sum()

dados.hist(bins=15,figsize = (15,10))
plt.tight_layout()
plt.show()

plt.hist(data=dados, x='Quality (1-5)',bins=15, color='purple')
plt.title('Gráfico de distribuição das notas de qualidade')
plt.show()

var_quali = dados.select_dtypes(include='object')

var_quali.nunique().T

dados['Blemishes (Y/N)'].value_counts()

dados_inte = dados.iloc[:, 0:4].columns.to_list()
dados_inte.append('HarvestTime (days)')
dados_inte
#Salvando as variaveis de interesse que segue uma disttribuição normal

var_inter = dados[dados_inte]



fig, ax = plt.subplots(3,2, figsize=(15,10))
sns.boxplot(data=dados, x='Color', y='Size (cm)',ax = ax[0,0])
ax[0,0].set_title(f'Boxplot of Size by Color')
ax[0,0].set_xlabel('Color')
ax[0,0].set_ylabel('Size')
ax[0,0].tick_params(axis='x', rotation=45)

#gráfico 2
sns.boxplot(data=dados, x='Color', y='Weight (g)',ax = ax[0,1])
ax[0,1].set_title(f'Boxplot of Weight by Color')
ax[0,1].set_xlabel('Color')
ax[0,1].set_ylabel('Weight (g)')
ax[0,1].tick_params(axis='x', rotation=45)
#gráfico 3

sns.boxplot(data=dados, x='Color', y='Brix (Sweetness)',ax = ax[1,0])
ax[1,0].set_title(f'Boxplot of Sweetness by Color')
ax[1,0].set_xlabel('Color')
ax[1,0].set_ylabel('Brix (Sweetness)')
ax[1,0].tick_params(axis='x', rotation=45)

#gráfico 4
sns.boxplot(data=dados, x='Color', y='pH (Acidity)',ax = ax[1,1])
ax[1,1].set_title(f'Boxplot of Acidity by Color')
ax[1,1].set_xlabel('Color')
ax[1,1].set_ylabel('pH (Acidity)')
ax[1,1].tick_params(axis='x', rotation=45)

#gráfico 5

sns.boxplot(data=dados, x='Color', y='HarvestTime (days)',ax = ax[2,0])
ax[2,0].set_title(f'Boxplot of HarvestTime by Color')
ax[2,0].set_xlabel('Color')
ax[2,0].set_ylabel('HarvestTime (days)')
ax[2,0].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()

#grafico de correlação

dados['Blemishes (Y/N)'] = dados['Blemishes (Y/N)'].apply(lambda x: 1 if 'Y' in x else 0)

X = dados.drop('Quality (1-5)', axis=1)
y = dados['Quality (1-5)']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

X_train.isna().sum()

X_train['Blemishes (Y/N)'].unique()

#X_train = X_train.drop('Variety', axis=1)
#X_test = X_test.drop('Variety', axis=1)
onehot = encoding.OneHotEncoder(variables=['Color','Variety'])
onehot.fit(X_train)
X_train = onehot.transform(X_train)
X_test = onehot.transform(X_test)

scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

meu_pipeline = pipeline.Pipeline([
    ('onehot', encoding.OneHotEncoder(variables=['Color','Variety'])),
    ('scaler', StandardScaler())
])


#RandomForest Regressor
modelo = RandomForestRegressor(random_state=42)
modelo.fit(X_train, y_train)
y_pred_randomForest= modelo.predict(X_test)

'''import pandas as pd
import matplotlib.pyplot as plt

importancias = modelo.feature_importances_
colunas = X_train.columns

pd.Series(importancias, index=colunas).sort_values(ascending=False).plot(kind='bar')
plt.title('Importância das variáveis')
plt.show()'''

#validação
mse = mean_squared_error(y_test, y_pred_randomForest)
r2 = r2_score(y_test, y_pred_randomForest)

print(f'MSE do RandomForest: {mse}')
print(f'R2 do RandomForest: {r2}')

from sklearn import linear_model
reg = linear_model.LinearRegression()
reg.fit(X_train, y_train)
y_pred_linear = reg.predict(X_test)

mse_linear = mean_squared_error(y_test, y_pred_linear)
r2_linear = r2_score(y_test, y_pred_linear)

print(f'MSE do LinearRegression: {mse_linear}')
print(f'R2 do LinearRegression: {r2_linear}')

"""## Testando o modelo como um problema de classificação
Depois de tentar criar bons modelos de regressão, acabei notando que o desempenho estava ruim e não tinha muito o que fazer em relaçãa e engenharia de varíaveis, então decidir transformar nossa variavel target em classes, assim talvez o ruído atrapalhasse menos o desemepneho
"""

#As variaveis de entre 0 e 1.5 entram no grupo 1.5, as de 1.5 a 2.5 entram no grupo de 2.5 e assim sucessetivamente
'''
1.2 → Classe 0 (≤1.5)

2.0 → Classe 1 (1.5–2.5]

3.7 → Classe 3 (3.5–4.5]

4.8 → Classe 4 (>4.5)

2.9 → Classe 2 (2.5–3.5]

1.7 → Classe 1 (1.5–2.5]

'''
thresholds = [1.5,2.5, 3.5, 4.5]

y_discrete = np.digitize(y, bins=thresholds)



X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y_discrete, test_size = 0.2, random_state = 42)



X_train2 = meu_pipeline.fit_transform(X_train2)
X_test2 = meu_pipeline.transform(X_test2)

logistic = linear_model.LogisticRegression()
logistic.fit(X_train2, y_train2)
y_pred_logistic = logistic.predict(X_test2)
y_proba_logistic = logistic.predict_proba(X_test2)

tree_acurracy = metrics.accuracy_score(y_test2, y_pred_logistic)
f1_score = metrics.f1_score(y_test2, y_pred_logistic, average='weighted')

print(f'F1-Score do modelo: {f1_score}')
print(f'Acurácia do modelo: {tree_acurracy}')

cm = confusion_matrix(y_test2,y_pred_logistic)
labels = ['Classe 0', 'Classe 1', 'Classe 2', 'Classe 3','Classe 4']

dis = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)
dis.plot(cmap='Blues')
plt.show()

tree = RandomForestClassifier()
tree.fit(X_train2, y_train2)
y_pred_forest = tree.predict(X_test2)

forest_acurracy = metrics.accuracy_score(y_test2, y_pred_forest)

f1_score_forest = metrics.f1_score(y_test2, y_pred_forest, average='weighted')

#Usando o weighted pq a nossas classes são desbalanceadas, então algumas classes vão receber mais peso que outras

print(f'F1-Score do modelo: {f1_score}')
print(f'Acurácia do modelo: {tree_acurracy}')

cm_forest = confusion_matrix(y_test2,y_pred_forest)
labels = ['Classe 0', 'Classe 1', 'Classe 2', 'Classe 3','Classe 4']

dis = ConfusionMatrixDisplay(confusion_matrix=cm_forest, display_labels=labels)
dis.plot(cmap='Blues')
plt.show()

meu_pipeline = pipeline.Pipeline([
    ('onehot', encoding.OneHotEncoder(variables=['Color','Variety'])),
    ('scaler', StandardScaler()),
    ('modelo', RandomForestClassifier())
])

X_trainf, X_testf, y_trainf, y_testf = train_test_split(X, y_discrete, test_size = 0.2, random_state = 42)


meu_pipeline.fit(X_trainf,y_trainf)

import joblib 

joblib.dump(meu_pipeline, 'modelo_treinado.pkl')